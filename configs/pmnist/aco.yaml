exp_name: Permuted MNIST
run_name: pmnist_aco
method: aco

mlruns_dir: results/mlruns
result_folder: results/pmnist
dataroot: ~/dataset
cuda: true
num_workers: 8

# These parameters can be overwritten by run/run_experiment.py
input_size: 28 # Model input size: 1 for RNN, 784 for MLP
pixel_in_input: 28 # Used to produce permutation and image sequence shape. 1 for MLP or RNN with pixel MNIST. 28 for RNN with row-MNIST.
rehe_patterns: 40 # Number of rehearsal patterns per class in the memory. This controls all type of rehearsal.
rehe_patterns_val: 10 # Number of rehearsal patterns per class in the memory. This controls all type of rehearsal.

# TASK CONFIGURATION
exp_type: mnist
split: false # Use split MNIST
sequential: false # permute images if false
n_tasks: 10
output_size: 10
max_label_value: 10 # if real value is greater, a % op will be applied on it.

# Model Hyperparameters
models: aco_lstm
epochs: 20
end_task_epochs: 1
hidden_size_rnn: 256
layers_rnn: 1
orthogonal: false # Use orthogonal recurrent matrixes
expand_output: 0 #Expand output layer dynamically

# OPTIMIZER
weight_decay: 0
learning_rate: 1e-3
batch_size: 128
clip_grad: 5
use_sgd: False

# EXTRAS
not_test: false
not_intermediate_test: false
monitor: true # monitor metrics
save: true # save models

# Replay Memory
patterns_per_class_per_batch: 20 # can be -1 (disable this option, not rehearsal), 0 (add a minibatch equally split among classes) or >0 (specify patterns per class per minibatch)
patterns_per_class_per_batch_val: 10 # can be -1 (disable this option, not rehearsal), 0 (add a minibatch equally split among classes) or >0 (specify patterns per class per minibatch)

# ACO Parameters
aco_init_value: 1.0
num_ant: 65536
aco_evaporation_rate: 0.05
aco_reward_coef: 1e-5
aco_update_rule: 1
